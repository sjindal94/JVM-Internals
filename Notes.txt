Course: https://www.udemy.com/course/java-application-performance-and-memory-management/

JVM
* JVM itself is written in C and C++.
Flags info: https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html
Tunings learnt:
StringTableSize
CodeCacheExpansionSize
InitialCodeCacheSize
ReservedCodeCacheSize
Interning a string


** Chapter2
* has just in time compilation. Converts bytecode to native code for most frequenntly used bits of code, for efficiency.

* -XX:+PrintCompilation
 72         25                  %                        4       PrimeNumbers::isPrime @ 2 (35 bytes)
seq no.  compilation_order.   placed in code 
                             cache(highest possible   
                               efficiency).   


0-4 numbers are compilation depth, then the piece of code. 0 means none(so interpreted).

* C1 and C2 compilers.  
C1 has 3 levels of native compilation. C2 has the 4th level.
Based of profiling output, JVM decides the level of compilation. It can even put that piece in special place called code cahce for efficieny.

* -XX:+UnlockDiagnosticVMOptions option that unlocks diagnostic JVM options. 

* -XX:+LogCimpilation Enables logging of compilation activity to a file named hotspot.log in the current working directory. You can specify a different log file path and name using the -XX:LogFile option.



* Tuning: Code Cache size
Moving code in and out of code cahce can happen

-XX:+PrintCodeCache - to see cahce size available and used. Max is 32Mb/64Mb.

To change
XX:InitialCodeCacheSize (Initial code cache size (in bytes))
XX:ReservedCodeCacheSize (Reserved code cache size (in bytes) - maximum code cache size)
XX:CodeCacheExpansionSize (Code cache expansion size (in bytes))



* Use JConsole to monitor the code cache size, uses extra ~2Mb of codecahce for JConsole compilation by JVM.

**Chapter 4 Memory management

* Stacks - Each Java thread has it's own stack and push and pops data as it enters/exits blocks of code. Stack only stores primitive data types. ints/doubles. All data in our application is accessed via the stack, either fully within or by a reference.
* Heaps - For storing big complex objects, also shared across all Java threads for passing around objects. String / Integer/ Customer. The pointer to that object is stored on the stack.




**Chapter 5 Passing objects
* Java always pass variable by value and not by reference. So a new copy is always made. For primitives it's the actual data, for objects, it's the reference variable.
* final variable cannot change, final method cannot be overridden, final class cannot be subclassed. Final gives JVM, do inlining for optimization. final variables can be initialized separately but cannot be changed. 
but,
final c= new customer("Susan") will error
c.setName("Susan") will not. as only the reference is fixed by final.
* Const correctness was never implemented in Java.
* stringvariable.toLowerCase() creates a new string, which is immediately ready for garbage collection if there is no assignment.


**Chapter 7 Escaping Reference
Giving access to objects with only getters of local variables to clients.
Caller can delete or mangle with the object.
Strategy 1) Making the class iterable. Still client can do it.remove() or it.clear().
Strategy 2) returning new Object() when doing getObject(). But now it causes confusion. Time and memory will be impacted whenever there is a get, but it is still not a big performance issue.
Strategy 3) returning immutable collection by doing Collections.unmodifiableMap(records) (<java10) or Map.copyof(records) (>java10). If records was already immutable, <java10 would always create a new object, but >java10 just returns the same object. (Slight performance improvements).
Strategy 4) For non collections object, this can heppen, records.find("John").setName("Jane").
To avoid that, we create a copyconstructor to Customer Class and then return by return new Customer(records.get(name)).
Strategy 5) Use Interfaces to provide only a ready only copy of the object. Malicious client can cast it back to original Customer class, but it still doesn't change the original data.
Strategy 6) Using modules from JPMS - Java Platform Module System (>java9).



**Chapter 9 Metaspace and internal JVM memory management.
* Stores metadata around class names, like which methods are to be interpreted or compiled etc.
* static primitives and reference to static object(stored in heap) are stored in Metaspace.
* Unlike stack, variables on metaspace are always there and never garbage collected.
* Before metaspace, <=java7, PermGen was there, and there were issues with it like OutOfMemoryError:PermGen. So it is now replaced.
* Modern JVMs can put an object on stack itself if it knows that it is not going to be used outside the block.
* String optimizations: 
 String one = "one";
 String two = "two";
JVM will use the same heap object for the two references, because strings are immutable and so it is safe.
one.equals(two) - only checks the underlying values;
one == two - checks if both the physical objects are same.
This happens because JVM maintains a String Pool(implemented as a hashmap and lives in heap).
Integer i = 76;
String three = i.toString();
four = "76";
three != four. these are different. Although JVM can be optimized for String deduplication.

* To manually do the above use i.toString().intern().



** Chapter 10 Tuning JVM's Memory Settings
* -XX:+PrintStringTableStatistics -- to understand the sizew and density of string pool. Denser the string pool, slower the application runs.
* then number of buckets in string pool is always chosen to be a Prime number. Can be adjusted using -XX:StringTableSize. Tuning: StringTableSize
* Tuning heapSize:
-XX:+UnlockDiagnosticVMOptions provides details on heap size. MaxHeapSize and InitialHeapSize.
If heap size is small, for example to hold the StringPoolTable, the program crashes with the error OutOfMemoryError: Java heap space.
Generally, it happens because of memory leak issues. Lower it to see if your application is running efficiently.
If you already know that your application would need atleast x heapsize, it is advisable to set that as InitialHeapSize.
Shortcuts for these, -Xmx and -Xms. Example: -Xms1g (without equal sign).



** chapter 11 Garbage Collection
* Java is a managed language. JVM works out when objects are no longer needed. In earlier versions of non-managed languages, server restart would be required to free memory. This is called mamory leak.
* Any object on heap which cannot be reached is eligible for garbage collection. An object can be referenced from another unreachable objact in heap, but JVM should be intelligent enough to detect that. (Circular references). Any object that is unreachable from the stack or from Metaspace.
* We can suggest JVM to run gc on an object. System.gc()/ Runtime.getRuntime().gc().
* Due to an optimization in java11, running GC can actually return the unused memory from JVM's hold back to OS.
* Running gc by yourself is not a good idea, as GC may impact the processing of your application.
* When gc is run, finalize() method of that object is called. But this is deprecated since java9. This is because, finalize method does not guarantee, the code will be run as, for example, the application itself can finish before complete garbage collection of all objects happen. So putting resource.close() calls in finalize() method is never a good idea. Putting a never ending loop in the finalize method, or any hung state, can potentially stop the GC itself.


** Chapter 14 Generational Garbage Collection
* Generally follow "Mark and Sweep" process. All threads in the application are paused("Stop the world"). Checks all variables in the stack adn metaspace and follows the reference. All used memory space is marked and in the second step, everything else is garbage collected. The objects are also relocated to a conitguous block of memory to fix fragmentation issues.
* Heap is divided into young and old generation. Young is very small and has new objects. GC only runs the young generation space and any surviving objects are moved to the old generation. Minor collection is GC on young generation space(fraction of a second). Major collection(a few seconds) is switched on if needed to sweep the old generation space. Compaction will also take place here.
* Young generation is divided into Eden, s0 and s1 spaces.
- 1st GC happens on Eden, survivors are moved to s0.
- 2nd GC happens on Eden and s0, survivors are moved to s1 with compaction.
- 3nd GC happens on Eden and s1, survivors are moved to s0 with compaction.
and so on... At any time, either od the s0 or s1 is completely empty, which is wastage but gives performace boost.
JVM also manages the sizes of the 3 spaces and changes them dynamically for optimal performances.
A configurable times is set for long surviving objects to be moved to old generation.

** Chapter 15 Garbage Collector tuning and selection
- Monitoring Garbage Collection using -verbose:gc
- GC = Minor garbage collection, and full GC is major garbage collection
- -XX:-UseAdaptiveSizePolicy - to disable 
- run jps to know the pid of running java programs
- run jinfo -flag UseAdaptiveSizePolicy 99467 to know if a particular flag is turned on for a program.
- -XX:NewRatio=n (default = 2) Old generation size/ new generation size
- -XX:SurvivorRatip=n (default = 8) S0 and S1 have 1/8th of memory each and Eden has 6/8 of memory from young generation.
- -XX:MaxTenuringThreshold (default = 15, max = 15) How many generations should an object survive before it becomes part of the old generation.


* Types of Collector:
- Serial: use single thread. Good when you want other applications to use processing while gc is running. Most commonly when your app is running a background task. Performance of your app is not important but other apps on the server needs to perform optimally. -XX:+UseSerialGC
- Parallel: if you ahve multicore processors, then use this. Also called throughput collector and is better performing than SerialGC. By default.
- Mostly Concurrent: Pauses application during marking process but resumes it when sweeping. 2 types:
  - -XX:UseConcMarkSweepGC (default in java9)
  - -XX:UseG1GC (improved version and a default in java10)

* G1GC
- S0 is small and S1 is large and after first GC, objects move to old generation
- Space is divided into 2048 regions and some of the regions are marked as eden, s0, s1 and old spaces. After young GC happens, different parts of the heap are marked again.
- Major GC picks those old regions which are totally garbages and clear them first.
- Tuning G1GC
 - -XX:ConcGCThreads=n :  number of threads for GC
 - -XX:InitiatingHeapOccupancyPercent=n : default memory 45% of full when the GC kicks in

- String de-deplication in G1GC -XX:UseStringDeduplication
 - G1GC will mdedupliucate and change references of pointers that use the same string with the same hashcode.
 - Good to use when you know you will have a lot of duplicate strings that will live for quite a long time and these strings are not in StringPool and you are in a memory constraint environment.


** Extra on G1GC
https://www.oracle.com/technical-resources/articles/java/g1gc.html
The Garbage First Garbage Collector (G1 GC) is the low-pause, server-style generational garbage collector for Java HotSpot VM. The G1 GC uses concurrent and parallel phases to achieve its target pause time and to maintain good throughput. When G1 GC determines that a garbage collection is necessary, it collects the regions with the least live data first (garbage first).

A garbage collector (GC) is a memory management tool. The G1 GC achieves automatic memory management through the following operations:

Allocating objects to a young generation and promoting aged objects into an old generation.
Finding live objects in the old generation through a concurrent (parallel) marking phase. The Java HotSpot VM triggers the marking phase when the total Java heap occupancy exceeds the default threshold.
Recovering free memory by compacting live objects through parallel copying.

Additional blogs
https://anthonyfisk.blogspot.com/2014/06/on-java-garbage-collection-analysis.html
https://product.hubspot.com/blog/g1gc-fundamentals-lessons-from-taming-garbage-collection


** Chapter 20 How lists work
8 types of lists
ArrayList
CopyOnWriteArrayList
LinkedList
AttributeList -- used with managed beans
RoleList -- used with Role objects
RoleUnresolvedList -- used with Role objects
Stack
Vector

* CopyOnWriteArrayList - Is a thread safe version of ArrayList, and is too costly, but may be efficient if traversal/retrieval vastly outnumber mutations. Everytime, we mutate the list, a copy of the list would be created. Usage:
- Multi threaded applications
- Multiple threads accessing the same list
- Lots of iterations and reads
- Few writes/ deletes/ additions


* Arraylist
- Instantiation creates a list with 10 elements inside. .size() will return 0 but internally it use up 10 element space.
- When 11th item is being added, a new bigger list if created first and data copied.
- implementation of Arraylist lives in lib/src/java.base/java/util/ArrayList.java
- DEFAULT_CAPACITY = 10
- Capacity increases by half of current size, newCapacity = oldCapacity + (oldCapacity >> 1)
- So better initialize the arraylist to expected max size for performance improvements. The .size() will still return 0 for empty list but capacity is what is expected.
- implements a marker interface called RandomAccess with no methods.
- Unlike maps, objectc position for access is calculated as they are contiguous.

* Vector
- Just like ArrayList but thread-safe.
- So we can use CopyOnWriteArrayList, Vector, or ArrayList with synchronized block.


* Stack
- Stack is a child object of Vector
- LinkedList implements Deque and List interfaces so it's better to use that instead of stack.

* LinkedList
- has next and prev pointers and there is no concept of initial size for a LinkedList.

* Chosing a list type
- Adding to end of list - faster for LinkedList but might have performance issues with ArrayList when resizing happens.
- Adding to start of the list - faster for LinkedList, but expensive for ArrayList.
- Removing an item from the middle - Expensive for ArrayList becasue of shifting, also expensive for LinkedList.
- Sorting ArrayList or LinkedList perform almost equally. They both use the underlying Arrays.sort method, but for LinkedList it first have to conbverted to Arrays.



** Chapter 21 How Maps Work
- Initializing the hashmap creates initial array of 16 elements.
- Integer representation of the key is required(hashcode). key % size = bucket number
- Keys must be unique, but can have same hashcode or mod of hashcode.
- Objects are stored as a linkedList in the bucket. After a certain size of this list, it is converted to a treeMap for O(logN) worst case performance.
- Loadfactor = 0.75, hashmap grouw by doubling each time. Items need to be moved around when that happens.
	Map<String, Book> books = new HashMap<>(500, 0.6f);
- Size of hashmap is always a power of 2.






Why choose a prime number?

Consider the set of keys 𝐾={0,1,...,100} and a hash table where the number of buckets is 𝑚=12. Since 3 is a factor of 12, the keys that are multiples of 3 will be hashed to buckets that are multiples of 3:

Keys {0,12,24,36,...} will be hashed to bucket 0.
Keys {3,15,27,39,...} will be hashed to bucket 3.
Keys {6,18,30,42,...} will be hashed to bucket 6.
Keys {9,21,33,45,...} will be hashed to bucket 9.
If 𝐾 is uniformly distributed (i.e., every key in 𝐾 is equally likely to occur), then the choice of 𝑚 is not so critical. But, what happens if 𝐾 is not uniformly distributed? Imagine that the keys that are most likely to occur are the multiples of 3. In this case, all of the buckets that are not multiples of 3 will be empty with high probability (which is really bad in terms of hash table performance).

This situation is more common that it may seem. Imagine, for instance, that you are keeping track of objects based on where they are stored in memory. If your computer's word size is four bytes, then you will be hashing keys that are multiples of 4. Needless to say that choosing 𝑚 to be a multiple of 4 would be a terrible choice: you would have 3𝑚/4 buckets completely empty, and all of your keys colliding in the remaining 𝑚/4 buckets.

In general:

Every key in 𝐾 that shares a common factor with the number of buckets 𝑚 will be hashed to a bucket that is a multiple of this factor.

Therefore, to minimize collisions, it is important to reduce the number of common factors between 𝑚 and the elements of 𝐾. How can this be achieved? By choosing 𝑚 to be a number that has very few factors: a prime number.


